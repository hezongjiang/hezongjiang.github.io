---
title: AlphaGo 的“前世今生”
catalog: true
date: 2018-05-21 11:46:02
subtitle: 浅谈AlphaGo
header-img: "alpha_go.jpg"
tags:
- 机器学习
- 天方夜谭
---
## 一、AlphaGo 的“前世”——深蓝——蛮算的“硬汉”
1996 年 2 月，在美国费城举行了一项别开生面的国际象棋比赛，报名参加比赛者包括了 “深蓝”计算机 和 当时世界棋王 卡斯帕罗夫。

比赛最后一天，世界棋王卡斯帕罗夫对垒“深蓝”计算机。在这场人机对弈的6局比赛中，棋王卡斯帕罗夫以 4：2 战胜计算机“深蓝”，获得 40 万美元高额奖金。人胜计算机，首次国际象棋人机大战落下帷幕。比赛在 2 月 17 日结束。其後研究小组把深蓝加以改良。

次年，也就是1997 年 5 月 11 日，在人与计算机之间挑战赛的历史上可以说是历史性的一天。

![1997年电脑深蓝首次战胜国象棋王卡斯帕罗夫](https://tva1.sinaimg.cn/large/006y8mN6gy1g8gbl5hycxj30dw08u3z0.jpg)

计算机在正常时限的比赛中首次击败了等级分排名世界第一的棋手。加里·卡斯帕罗夫以 2.5:3.5 （1胜2负3平）输给 IBM 的计算机程序 “深蓝”。机器的胜利标志着国际象棋历史的新时代。

![落败](https://tva1.sinaimg.cn/large/006y8mN6gy1g8gbmacdl2j30hs0bkwfq.jpg)

其中，比赛的转折点出现在第二局。

卡斯帕罗夫第一局获胜，感觉很好。但在第二局中，双方却打得不可开交。在第 36 步棋时，电脑的做法让卡斯帕罗夫不寒而栗。在当时的情况下，几乎所有顶尖国际象棋程序都会攻击卡斯帕罗夫暴露在外的皇后，但深蓝却走出了一步更为狡猾的棋，最终的效果也更好。这令卡斯帕罗夫对电脑另眼相看。

对卡斯帕罗夫和所有旁观者来说，深蓝突然不再像电脑一样下棋（它顶住诱惑，没有攻击皇后），反而采取了只有最聪明的人类大师级选手才有可能使用的策略。通过在卡斯帕罗夫面前深藏不漏，IBM成功让人类低估了它的水平。

他的斗志和体力在随后3局被拖垮，在决胜局中，仅 **19** 步就宣布放弃。

后来，IBM拒绝了卡斯帕罗夫的再战请求，拆卸了“深蓝”。卡斯帕罗夫虽然后来多次挑战电脑战平，却无法找“深蓝”“复仇”，留下永久的遗憾。 

在今天看来，“深蓝”还算不上智能，它主要依靠强大的计算能力穷举所有路数来选择最佳策略：“深蓝”靠硬算可以预判12步，卡斯帕罗夫可以预判10步，两者高下立现。

![深蓝计算机](https://tva1.sinaimg.cn/large/006y8mN6gy1g8gbmz33guj307g0b7weo.jpg)

## 二、AlphaGo 的“今生”

在 AlphaGo 诞生之前，计算机在除围棋之外，几乎所有棋类游戏上战胜了人类，唯独围棋没有被攻克，为什么呢？

![AlphaGo](https://tva1.sinaimg.cn/large/006y8mN6gy1g8gbnixg3cj30et08c0ss.jpg)

围棋游戏只有两个非常简单的规则，而其复杂性却是难以想象的，一共有 10 的 170 次方种可能性，这个数字之大，以至于用当今世界最强大的计算系统，算几十年也算不完，是没有办法穷举出围棋所有的可能结果的。所以，计算机需要一种更加聪明的方法。

直到 2016 年，AlphaGo 第一版发表在了 Nature 自然杂志上，这可是牛逼得不要不要的期刊。

![Nature 杂志封面](https://tva1.sinaimg.cn/large/006y8mN6gy1g8gboggofcj307o0a8431.jpg)

而刚过去一年，Google DeepMind 又在 Nature 上发表了一篇 AlphaGo 的改进版——AlphaGo Zero，同样的围棋 AI，竟然在自然杂志上发了两次！赞叹他们的实力呀！

AlphaGo 战胜过欧洲冠军樊麾，韩国九段棋手李世石，而后又赢了世界冠军柯洁，种种迹象表明，人类已经失守最拿手的围棋了。这些围棋高手一个个都表示 AlphaGo 走到了他们想不到的地方，战胜了人类的生物极限。那 AlphaGo 又是怎么在策略上战胜人类的呢？很简单，它会做计划。

>在我被 AlphaGo 2:0 领先以后，我彻夜未眠。因为我一直在想我如何才能赢了它，它会不会有什么漏洞，哪怕是捡一盘也好啊！在第三局中，我竭尽全力以求一胜。因为在第二局的时候，我其实布局是领先的，布局的领先让我依稀看到了胜利的曙光。在第三盘中我跟它拼了！可是就在早早布局的阶段，我却出现了一个非常致命的失误。——引自柯洁的演讲

>棋至中盘，我努力寻找机会，可是 AlphaGo 实在是太完美了，它下出了让我感到寒冷的一步棋，令我感到绝望的一步棋。它下完之后，我知道我这盘棋是不可能赢了。我感到浑身都在颤抖，真的，寒冷地颤抖。我再也控制不住情绪，赶紧冲出对局室，找到一个无人的角落里哭了起来。因为即将到来的3:0，这样的结局对我来说实在是太绝望了。——引自柯洁的演讲

## 三、AlphaGo 背后的原理

阿尔法狗（AlphaGo）是通过两个不同神经网络合作来改进下棋。这就像有两个导师，每个都是多层神经网络。它们从多层启发式二维过滤器开始，去处理围棋棋盘的定位，就像图片分类器网络处理图片一样。经过过滤，13 个完全连接的神经网络层产生对它们看到的局面判断。这些层能够做分类和逻辑推理。

这些网络通过反复训练来检查结果，再去校对调整参数，去让下次执行更好。这个处理器有大量的随机性元素，所以人们是不可能精确知道网络是如何“思考”的，但更多的训练后能让它进化到更好。

![AlphaGo 原理](https://tva1.sinaimg.cn/large/006y8mN6gy1g8gboz7348j30kk06zwen.jpg)

**导师1号：策略网络（Policy network）**

![Policy network](https://tva1.sinaimg.cn/large/006y8mN6gy1g8gbpejb51j308i02rq3k.jpg)

AlphaGo 的第一个神经网络大脑是“策略网络（Policy Network）”，观察棋盘布局企图找到最佳的下一步。事实上，它预测每一个合法下一步的最佳概率，那么最前面猜测的就是那个概率最高的。这可以理解成“落子选择器”。

AlphaGo 团队首先利用几万局专业棋手对局的棋谱来训练系统，得到初步的“策略网络”。训练“策略网络”时，采用“深度学习”算法，基于全局特征和深度卷积网络 (CNN) 来训练，其主要作用是给定当前盘面状态作为输入，输出下一步棋在棋盘其它空地上的落子概率。

![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8gbqf0djfj308c087tah.jpg)

接下来，AlphaGo 采用左右互搏的模式，不同版本的 AlphaGo 相互之间下了 3000 万盘棋，利用人工智能中的“深度增强学习”算法，利用每盘棋的胜负来学习，不断优化和升级“策略网络”，同时建立了一个可以对当前局面估计白棋和黑棋胜率的“价值网络”。

**导师2号：价值网络（Value network）**

![Value network](https://tva1.sinaimg.cn/large/006y8mN6gy1g8gbqv6ny0j308l02mt9b.jpg)

AlphaGo 的第二个大脑相对于落子选择器是回答另一个问题。不是去猜测具体下一步，它预测每一个棋手赢棋的可能，在给定棋子位置情况下。这个局面评估器就是“价值网络（Value Network）”，通过整体局面判断来辅助落子选择器。所以，人类棋手在跟 AlphaGo 下棋时会感到非常不习惯，刚才还在这里厮杀的你死我活，AlphaGo 突然转移占地了，因为另外一处有更大的“价值”，虽然我们人类也知道要这样做，但是在正在厮杀的过程中，沉默成本太大，真的很少有人能做到这点。

![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8gbrjgb1qj308c08gq5z.jpg)

然后，AlphaGo 通过吸收人类**几千年**来优秀的棋谱，不断学习优化 策略网络 和 价值网络，从而战胜了欧洲冠军樊麾，韩国九段棋手李世石，而后又赢了世界冠军柯洁。

实际对局时，AlphaGo 通过“蒙特卡罗树搜索”来管理整个对弈的搜索过程。

![AlphaGo 下棋](https://tva1.sinaimg.cn/large/006y8mN6gy1g8gbryp3f9j308808576a.jpg)

首先，通过“策略网络”，AlphaGo 可以优先搜索本方最有可能落子的点（通常低于10个）。对每种可能再通过“估值网络”评估胜率，分析需要更进一步展开搜索和演算的局面。综合这几种工具，辅以超级强大的并行运算能力，AlphaGo 在推演棋局变化和寻找妙招方面的能力，已经远超人类棋手。

根据资料，最高配置的 AlphaGo 分布式版本，配置了 1920 个 CPU 和 280 个 GPU，同时可以跑 64 个搜索线程，这样的计算速度就好像有几十个九段高手同时在想棋，还有几十个三段棋手帮着把一些难以判断的局面直接下到最后，拿出结论，某一位人类棋手要与对抗，确实难以企及。

但是，这并不是重点。

## 四、AlphaGo Zero

终于说到重点了~~

Zero 英文意思是：零。除了围棋最基本规则（棋盘的几何学定义，轮流落子规则，终局输赢计算，打劫等），它就是一张白纸。放弃参考任何人类棋谱，完全自我学习。

![AlphaGo Zero](https://tva1.sinaimg.cn/large/006y8mN6gy1g8gbsf2nuij30dv08r771.jpg)

如果你和一个有人类老师的 AlphaGo 交手，那可能还会在它背后看到人类下棋的影子。但是 AlphaGo Zero，完全是一个无师自通的家伙，和它下棋，你可能闻到很浓烈的机械味。但从另一方面想，这样的 AlphaGo 打破了数千年来人类下棋思维的限制，探索了人类想不到的下棋境界，学会了一个崭新的下棋方式。

仅仅经过 **3** 天的训练后，这套系统已经可以击败 AlphaGo Lee，也就是击败韩国顶尖棋手李世石的那套系统，而且比分高达100：0。经过 40 天训练后，它总计运行了大约 2900 万次自我对弈，使得 AlphaGo Zero 击败 AlphaGo Master，也就是击败世界冠军柯洁的系统，比分为 89：11。要知道职业围棋选手一生中的正式比赛也就一千多局， 而 AlphaGo Zero 却进行了 2900 万次对局。

![AlphaGo Zero 训练效果](https://tva1.sinaimg.cn/large/006y8mN6gy1g8gbssoqkhj30o709gq37.jpg)

在技术层面来说，AlphaGo Zero 使用的不再是之前提到的两套神经网络系统，而是将它们融合成一个神经网络系统，这样做能更有效利用资源，学习效果更好。其关键在于采用了新的{% post_link 强化学习 强化学习 %}，并给该算法带了新的发展。

![柯洁对 AlphaGo Zero 的看法](https://tva1.sinaimg.cn/large/006y8mN6gy1g8gbtnf4r1j30g70fmjsp.jpg)

而且，它不再仅仅使用 GPU，转而添加了自家的专门为机器学习打造的 TPU，而且使用的硬件个数也在逐步降低，然而学习的效果却不断上升。在短短 40 天没有老师教的训练中，AlphaGo Zero 超越了他所有的前辈，在这个时候，我相信它真正做到了在围棋场上无人能敌了。

最后，正如 AlphaGo 之父 David Silver 所说，一个无师自通 AlphaGo 的产生，并不仅仅意味着我们的 AI 能在围棋场上战胜人类，放眼未来，它还意味着，在更多方面，我们能用这样的 AI 创造出更多人类历史上的新篇章。

围棋场上，无论谁赢，最终获胜的都是人类自己。
